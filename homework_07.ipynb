{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW07: Parsing\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           label                                          title  \\\n39815      world            Frenchman Shot Dead in Saudi Arabia   \n44834      sport                  Stars won't leave home for it   \n1945    sci/tech  Microsoft Updates Its IBM Connectivity Server   \n4037    sci/tech     An Aspirin a Day -- Good Medicine For Many   \n119361     sport     Former Blue Jays Manager Mattick Dies (AP)   \n\n                                                     lead  \\\n39815    JEDDAH (Reuters) - A Frenchman was shot dead ...   \n44834   Purses overflowing with cash, exotic locales, ...   \n1945    Microsoft on Tuesday unveiled the 2004 version...   \n4037    Most people have heard that taking a small dos...   \n119361  AP - Bobby Mattick, who managed the Toronto Bl...   \n\n                                                     text  \n39815   Frenchman Shot Dead in Saudi Arabia  JEDDAH (R...  \n44834   Stars won't leave home for it Purses overflowi...  \n1945    Microsoft Updates Its IBM Connectivity Server ...  \n4037    An Aspirin a Day -- Good Medicine For Many Mos...  \n119361  Former Blue Jays Manager Mattick Dies (AP) AP ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title</th>\n      <th>lead</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39815</th>\n      <td>world</td>\n      <td>Frenchman Shot Dead in Saudi Arabia</td>\n      <td>JEDDAH (Reuters) - A Frenchman was shot dead ...</td>\n      <td>Frenchman Shot Dead in Saudi Arabia  JEDDAH (R...</td>\n    </tr>\n    <tr>\n      <th>44834</th>\n      <td>sport</td>\n      <td>Stars won't leave home for it</td>\n      <td>Purses overflowing with cash, exotic locales, ...</td>\n      <td>Stars won't leave home for it Purses overflowi...</td>\n    </tr>\n    <tr>\n      <th>1945</th>\n      <td>sci/tech</td>\n      <td>Microsoft Updates Its IBM Connectivity Server</td>\n      <td>Microsoft on Tuesday unveiled the 2004 version...</td>\n      <td>Microsoft Updates Its IBM Connectivity Server ...</td>\n    </tr>\n    <tr>\n      <th>4037</th>\n      <td>sci/tech</td>\n      <td>An Aspirin a Day -- Good Medicine For Many</td>\n      <td>Most people have heard that taking a small dos...</td>\n      <td>An Aspirin a Day -- Good Medicine For Many Mos...</td>\n    </tr>\n    <tr>\n      <th>119361</th>\n      <td>sport</td>\n      <td>Former Blue Jays Manager Mattick Dies (AP)</td>\n      <td>AP - Bobby Mattick, who managed the Toronto Bl...</td>\n      <td>Former Blue Jays Manager Mattick Dies (AP) AP ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1: \"world\", 2: \"sport\", 3: \"business\", 4: \"sci/tech\"}\n",
    "\n",
    "\n",
    "def replace_label(x):\n",
    "    return label_map[x]\n",
    "\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label)\n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=10000)  # # only use 10K datapoints\n",
    "# df = df.sample(n=100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#TODO preprocess the corpus using spacy or load the pre-processed corpus\n",
    "df[\"preprocessed\"] = df[\"text\"].apply(lambda x: nlp(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Iterable\n",
    "\n",
    "\n",
    "def extract_pairs(sent, which: str):\n",
    "    elems = [w for w in sent if w.dep_ == which]\n",
    "    return [(w.lemma_.lower(), w.head.lemma_.lower()) for w in elems]\n",
    "\n",
    "\n",
    "def get_most_common(items: Iterable, n: int = 10, verbose: bool = True) -> Counter:\n",
    "    counter = Counter()\n",
    "    for item in items:\n",
    "        counter.update(item)\n",
    "    if verbose:\n",
    "        for pair, counts in counter.most_common(n=n):\n",
    "            print(pair, counts)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[('frenchman', 'shoot'), ('that', 'mirror')]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO extract the subject-verbs pairs and print the result for the first document\n",
    "df[\"subj-verb-pairs\"] = df[\"preprocessed\"].apply(lambda x: extract_pairs(x, 'nsubj'))\n",
    "df.iloc[0][\"subj-verb-pairs\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-pron-', 'be') 447\n",
      "('official', 'say') 162\n",
      "('-pron-', 'have') 100\n",
      "('that', 'be') 89\n",
      "('-pron-', 'say') 73\n",
      "('company', 'say') 68\n",
      "('-pron-', 'take') 50\n",
      "('what', 'be') 46\n",
      "('this', 'be') 46\n",
      "('group', 'say') 44\n"
     ]
    }
   ],
   "source": [
    "##TODO create a list ranking the most common pairs and print the first 10 items\n",
    "counter_subj_verb = get_most_common(df[\"subj-verb-pairs\"], n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "[('dead', 'shoot'), ('attack', 'mirror'), ('exporter', 'destabilize')]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO do the same for verbs-object pairs ('dobj')\n",
    "df[\"verb-obj-pairs\"] = df[\"preprocessed\"].apply(lambda x: extract_pairs(x, 'dobj'))\n",
    "df.iloc[0][\"verb-obj-pairs\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('people', 'kill') 85\n",
      "('job', 'cut') 44\n",
      "('agreement', 'reach') 33\n",
      "('million', 'pay') 32\n",
      "('point', 'score') 31\n",
      "('lead', 'take') 28\n",
      "('rate', 'raise') 24\n",
      "('plan', 'announce') 22\n",
      "('39;t', 'win') 21\n",
      "('step', 'take') 20\n"
     ]
    }
   ],
   "source": [
    "counter_verb_obj = get_most_common(df[\"verb-obj-pairs\"], n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('saudi', 'city'), ('recent', 'attack'), ('large', 'exporter')]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO do the same for adjectives-nouns pairs ('amod')\n",
    "df[\"adj-noun-pairs\"] = df[\"preprocessed\"].apply(lambda x: extract_pairs(x, 'amod'))\n",
    "df.iloc[0][\"adj-noun-pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('third', 'quarter') 163\n",
      "('last', 'week') 121\n",
      "('next', 'year') 101\n",
      "('last', 'night') 101\n",
      "('first', 'time') 82\n",
      "('presidential', 'election') 68\n",
      "('last', 'month') 59\n",
      "('last', 'year') 59\n",
      "('next', 'week') 58\n",
      "('such', 'as') 56\n"
     ]
    }
   ],
   "source": [
    "##TODO create a list ranking the most common pairs and print the first 10 items\n",
    "counter_adj_noun = get_most_common(df[\"adj-noun-pairs\"], n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring cross label dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== subject-verbs ====================\n",
      "==================== verbs-object ====================\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "##TODO extract all the subject-verbs and verbs-object pairs for the verb \"win\"\n",
    "for k, counter in [('subject-verbs', counter_subj_verb), ('verbs-object', counter_verb_obj)]:\n",
    "    print('=' * 20, k, '=' * 20)\n",
    "    for subj, verb in itertools.islice(iter(counter), 10):\n",
    "        if verb == 'win':\n",
    "            print(subj, verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== sport ====================\n",
      "***** counter_subj_verb *****\n",
      "('-pron-', 'be') 175\n",
      "('-pron-', 'have') 36\n",
      "('this', 'be') 24\n",
      "('-pron-', 'take') 23\n",
      "('that', 'be') 22\n",
      "('-pron-', 'go') 20\n",
      "('-pron-', 'say') 17\n",
      "('-pron-', 'see') 16\n",
      "('-pron-', 'get') 16\n",
      "('-pron-', 'need') 15\n",
      "\n",
      "\n",
      "***** counter_verb_obj *****\n",
      "('point', 'score') 31\n",
      "('lead', 'take') 21\n",
      "('title', 'win') 20\n",
      "('medal', 'win') 17\n",
      "('game', 'miss') 16\n",
      "('point', 'have') 15\n",
      "('lead', 'give') 14\n",
      "('goal', 'score') 13\n",
      "('game', 'play') 12\n",
      "('39;t', 'wasn') 12\n",
      "\n",
      "\n",
      "==================== business ====================\n",
      "***** counter_subj_verb *****\n",
      "('-pron-', 'be') 68\n",
      "('company', 'say') 35\n",
      "('profit', 'rise') 28\n",
      "('group', 'say') 26\n",
      "('stock', 'rise') 25\n",
      "('quote', 'say') 25\n",
      "('corp.', 'say') 25\n",
      "('-pron-', 'cut') 24\n",
      "('inc.', 'say') 23\n",
      "('official', 'say') 21\n",
      "\n",
      "\n",
      "***** counter_verb_obj *****\n",
      "('job', 'cut') 39\n",
      "('million', 'pay') 24\n",
      "('rate', 'raise') 23\n",
      "('share', 'send') 20\n",
      "('agreement', 'reach') 18\n",
      "('profit', 'post') 15\n",
      "('loss', 'post') 15\n",
      "('profit', 'report') 12\n",
      "('rise', 'report') 11\n",
      "('stake', 'buy') 11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##TODO for each label create a list ranking the most common subject-verbs pairs and one for the most common verbs-object pairs\n",
    "counters = {}\n",
    "for label in df.label:\n",
    "    counters[label] = {\n",
    "        'counter_subj_verb': get_most_common(df.loc[df.label == label, 'subj-verb-pairs'], verbose=False),\n",
    "        'counter_verb_obj': get_most_common(df.loc[df.label == label, 'verb-obj-pairs'], verbose=False)}\n",
    "\n",
    "##TODO print the 10 most common pairs for each of the two lists for the labels \"sport\" and \"business\"\n",
    "for label in [\"sport\", \"business\"]:\n",
    "    print('=' * 20, label, '=' * 20)\n",
    "    for k, counter in counters[label].items():\n",
    "        print('*' * 5, k, '*' * 5)\n",
    "        for pair, counts in counter.most_common(n=10):\n",
    "            print(pair, counts)\n",
    "        print('\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}