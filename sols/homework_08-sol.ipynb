{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW08: Word Embeddings\n",
    "\n",
    "Remember that these homework work as a completion grade. **In this homework, we present two tasks and you can choose which one you want to solve. You only have to solve <span style=\"color:red\">one task</span> in this homework.**\n",
    "Task 1 is more guided and we evaluate document embeddings on a standard benchmark. Task 2 is very open-end and might be a starting point for your course project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "In this task, we evaluate different document embeddings on the English version of the [STS Benchmark](https://arxiv.org/pdf/1708.00055.pdf). The task is to determine how semantically similar two texts are and is a popular dataset to evaluate document embeddings, i.e. we want embeddings of two semantically similar documents to be similar as well. We provide a wordcounts baseline for this task and ask you to compute and evaluate embeddings for a selected sample of document embedding techniques.\n",
    "\n",
    "To evaluate, we follow [(Reimers and Gurevych, 2019)](https://arxiv.org/pdf/1908.10084.pdf) and compute the Spearman’s rankcorrelation between the cosine-similarity of thesentence embeddings and the gold labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\r\n",
      "--2021-06-08 08:28:28--  https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\r\n",
      "Resolving alt.qcri.org (alt.qcri.org)... 80.76.166.234\r\n",
      "Connecting to alt.qcri.org (alt.qcri.org)|80.76.166.234|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 87902 (86K) [application/zip]\r\n",
      "Saving to: ‘sts2017.eval.v1.1.zip’\r\n",
      "\r\n",
      "sts2017.eval.v1.1.z 100%[===================>]  85.84K   253KB/s    in 0.3s    \r\n",
      "\r\n",
      "2021-06-08 08:28:29 (253 KB/s) - ‘sts2017.eval.v1.1.zip’ saved [87902/87902]\r\n",
      "\r\n",
      "URL transformed to HTTPS due to an HSTS policy\r\n",
      "--2021-06-08 08:28:30--  https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\r\n",
      "Resolving alt.qcri.org (alt.qcri.org)... 80.76.166.234\r\n",
      "Connecting to alt.qcri.org (alt.qcri.org)|80.76.166.234|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 3138 (3.1K) [application/zip]\r\n",
      "Saving to: ‘sts2017.gs.zip’\r\n",
      "\r\n",
      "sts2017.gs.zip      100%[===================>]   3.06K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2021-06-08 08:28:30 (150 MB/s) - ‘sts2017.gs.zip’ saved [3138/3138]\r\n",
      "\r\n",
      "Archive:  sts2017.eval.v1.1.zip\r\n",
      "  inflating: STS2017.eval.v1.1/LICENSE.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/README.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track1.ar-ar.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track2.ar-en.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track3.es-es.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track4a.es-en.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track4b.es-en.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track5.en-en.txt  \r\n",
      "  inflating: STS2017.eval.v1.1/STS.input.track6.tr-en.txt  \r\n",
      "Archive:  sts2017.gs.zip\r\n",
      "   creating: STS2017.gs/\r\n",
      "  inflating: STS2017.gs/STS.gs.track1.ar-ar.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track2.ar-en.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track3.es-es.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track4a.es-en.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track4b.es-en.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track5.en-en.txt  \r\n",
      "  inflating: STS2017.gs/STS.gs.track6.tr-en.txt  \r\n"
     ]
    }
   ],
   "source": [
    "# obtain the data\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
    "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
    "\n",
    "!unzip sts2017.eval.v1.1.zip \n",
    "!unzip sts2017.gs.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('A person is on a baseball team.',\n 'A person is playing basketball on a team.',\n 2.4)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "def load_STS_data():\n",
    "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
    "        labels = [float(line.strip()) for line in f]\n",
    "    \n",
    "    text_a, text_b = [], []\n",
    "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            text_a.append(line[0])\n",
    "            text_b.append(line[1])\n",
    "    return text_a, text_b, labels\n",
    "\n",
    "text_a, text_b, labels = load_STS_data()\n",
    "text_a[0], text_b[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utils\n",
    "from scipy.stats import spearmanr\n",
    "def evaluate(predictions, labels):\n",
    "    print (spearmanr(predictions, labels)[0])\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6998056665685976\n"
     ]
    }
   ],
   "source": [
    "# Wordcounts baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(text_a + text_b)\n",
    "\n",
    "# encode documents\n",
    "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
    "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "##TODO train Doc2Vec on the texts in the dataset, compute cosine similarity of the resulting embeddings and evaluate\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk import word_tokenize\n",
    "docs = []\n",
    "for i in text_a + text_b:\n",
    "    docs.append(word_tokenize(i))\n",
    "\n",
    "doc_iterator = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]\n",
    "d2v = Doc2Vec(doc_iterator,\n",
    "                min_count=2, # minimum word count\n",
    "                window=5,    # window size\n",
    "                vector_size=25, # size of document vector\n",
    "                sample=1e-4, \n",
    "                negative=5, \n",
    "                workers=4, # threads\n",
    "                #dbow_words = 1 # uncomment to get word vectors too\n",
    "                max_vocab_size=1000) # max vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05212032836011226\n"
     ]
    }
   ],
   "source": [
    "text_a_encoded = d2v.docvecs.vectors_docs[:len(text_a)]\n",
    "text_b_encoded = d2v.docvecs.vectors_docs[len(text_a):]\n",
    "\n",
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with embeddings provided by spaCy\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text_a_encoded = [nlp(text).vector for text in text_a]\n",
    "text_b_encoded = [nlp(text).vector for text in text_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5210910398082091\n",
      "0.5210910398082091\n"
     ]
    }
   ],
   "source": [
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n",
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "##TODO do the same with universal sentence embeddings\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)\n",
    "\n",
    "embeddings_a = embed(text_a)\n",
    "embeddings_b = embed(text_b)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    text_a_encoded = session.run(embeddings_a)\n",
    "    text_b_encoded = session.run(embeddings_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8493103413219787\n",
      "0.8493103413219787\n"
     ]
    }
   ],
   "source": [
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(512,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dsdgfas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-fb344fb57424>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mdsdgfas\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dsdgfas' is not defined"
     ]
    }
   ],
   "source": [
    "for a,b in zip(text_a_encoded, text_b_encoded):\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    dsdgfas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 512)\n"
     ]
    }
   ],
   "source": [
    "print(text_a_encoded.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO do the same with SBERT embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = \"bert-base-nli-mean-tokens\"\n",
    "embedder = SentenceTransformer(model)\n",
    "text_a_encoded = embedder.encode(text_a)\n",
    "text_b_encoded = embedder.encode(text_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008164100246977\n"
     ]
    }
   ],
   "source": [
    "# predict cosine similarities\n",
    "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
    "\n",
    "# evaluate\n",
    "evaluate(predictions, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "Use your favorite document embeddings method to compute embeddings for a dataset you are interested in. Think of a method and provide some data visualization statistics (one method would be the path we have chosen in the notebook, i.e. cluster the embeddings with k-means and visualize low-dimensional representations of the document embeddings obtained by PCA). \n",
    "\n",
    "This task is very open and there is no right or wrong; If you want to use document embeddings in your course project, this is a chance to play around with those.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}