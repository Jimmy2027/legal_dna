{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: Word Embeddings\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can <span style=\"color:red\">not</span> skip one section this homework.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essay Feedback**\n",
    "\n",
    "Please provide feedback to two classmates' essays on Eduflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training word2vec**\n",
    "\n",
    "In this section, we train a word2vec model using gensim. We train the model on text8 (which consists of the first 90M characters of a Wikipedia dump from 2006 and is considered one of the benchmarks for evaluating language models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'num_records': 1701,\n 'record_format': 'list of str (tokens)',\n 'file_size': 33182058,\n 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n 'license': 'not found',\n 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n 'checksum': '68799af40b6bda07dfa47a32612e5364',\n 'file_name': 'text8.gz',\n 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n 'parts': 1}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "\n",
    "api.info(\"text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load(\"text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "##TODO train a word2vec model on this dataset, only consider words which appear at least 10 times in the corpus\n",
    "\n",
    "model = Word2Vec(dataset,  # list of tokenized sentences\n",
    "                 min_count=10,  # Minimum word count\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Similarities**\n",
    "\n",
    "gensim models provide almost all the utility you might want to wish for to perform standard word similarity tasks. They are available in the .wv (wordvectors) attribute of the model, more details could be found [here](https://radimrehurek.com/gensim/models/keyedvectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = model.wv\n",
    "word_vectors['arafat']\n",
    "word_vectors.save('vectors.kv')\n",
    "word_vectors = KeyedVectors.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prince', 0.7635866403579712), ('queen', 0.7095021605491638), ('kings', 0.7082085609436035), ('emperor', 0.7068253755569458), ('regent', 0.6904042363166809), ('vii', 0.6830312013626099), ('throne', 0.6775007247924805), ('sultan', 0.6710481643676758), ('aragon', 0.6708518266677856), ('viii', 0.6621804237365723)]\n"
     ]
    }
   ],
   "source": [
    "##TODO find the closest words to king\n",
    "print(word_vectors.most_similar('king'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "King is to man as woman is to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.6997\n"
     ]
    }
   ],
   "source": [
    "##TODO find the closest word for the vector \"woman\" + \"king\" - \"man\"\n",
    "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "most_similar_key, similarity = result[0]  # look at the first match\n",
    "print(f\"{most_similar_key}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Word Similarities** \n",
    "\n",
    "One common way to evaluate word2vec models are word analogy tasks. Let's check how good our model is on one of those. We consider the [WordSim353](http://alfonseca.org/eng/research/wordsim353.html) benchmark, the task is to determine how similar two words are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            A      B      y\n0       tiger    cat   7.35\n1       tiger  tiger  10.00\n2       plane    car   5.77\n3       train    car   6.31\n4  television  radio   6.77",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tiger</td>\n      <td>cat</td>\n      <td>7.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>plane</td>\n      <td>car</td>\n      <td>5.77</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>car</td>\n      <td>6.31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>television</td>\n      <td>radio</td>\n      <td>6.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !wget http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
    "# !tar xf ws353simrel.tar.gz\n",
    "\n",
    "path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
    "\n",
    "\n",
    "def df_maker(f):\n",
    "    for line in f:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        yield {'A': line[0], 'B': line[1], 'y': line[-1]}\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path) as f:\n",
    "        df = pd.DataFrame(data=df_maker(f))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            A      B      y  similarity\n0       tiger    cat   7.35    0.620412\n1       tiger  tiger  10.00    1.000000\n2       plane    car   5.77    0.435886\n3       train    car   6.31    0.535424\n4  television  radio   6.77    0.736855",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>y</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tiger</td>\n      <td>cat</td>\n      <td>7.35</td>\n      <td>0.620412</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>10.00</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>plane</td>\n      <td>car</td>\n      <td>5.77</td>\n      <td>0.435886</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>car</td>\n      <td>6.31</td>\n      <td>0.535424</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>television</td>\n      <td>radio</td>\n      <td>6.77</td>\n      <td>0.736855</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO compute how similar the pairs in the WordSim353 are according to our model\n",
    "##TODO if  aword is not present in our model, we assign similarity 0 for the respective text pair\n",
    "df['similarity'] = df.apply(lambda x: word_vectors.similarity(x.A, x.B) if (x.A in word_vectors) and (x.B in word_vectors) else 0, axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6083728930917283"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "##TODO compute spearman's rank correlation between our prediction and the human annotations\n",
    "spearmanr(df.y, df.similarity).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hendrik/opt/anaconda3/envs/legal_dna/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5420636159533704"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "en('apple').similarity(en('orange'))\n",
    "\n",
    "\n",
    "##TODO compute word similarities in the WordSim353 dataset using spaCy word embeddings\n",
    "##TODO compute spearman's rank correlation between these similarities and the human annotations\n",
    "# Don't worry if results are not too convincing for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hendrik/opt/anaconda3/envs/legal_dna/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": "            A      B      y  similarity  spacy_sim\n0       tiger    cat   7.35    0.620412   0.624192\n1       tiger  tiger  10.00    1.000000   1.000000\n2       plane    car   5.77    0.435886   0.608974\n3       train    car   6.31    0.535424   0.508821\n4  television  radio   6.77    0.736855   0.600423",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>y</th>\n      <th>similarity</th>\n      <th>spacy_sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tiger</td>\n      <td>cat</td>\n      <td>7.35</td>\n      <td>0.620412</td>\n      <td>0.624192</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>10.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>plane</td>\n      <td>car</td>\n      <td>5.77</td>\n      <td>0.435886</td>\n      <td>0.608974</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>car</td>\n      <td>6.31</td>\n      <td>0.535424</td>\n      <td>0.508821</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>television</td>\n      <td>radio</td>\n      <td>6.77</td>\n      <td>0.736855</td>\n      <td>0.600423</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spacy_sim'] = df.apply(lambda x: en(x.A).similarity(en(x.B)), axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "0.08738489440789854"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(df.y, df.spacy_sim).correlation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}